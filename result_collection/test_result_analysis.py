import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from algorithm.common.util.read_pkl import read_data


def calculate_precision_recall(data_list):
    """è®¡ç®—æ¯ä¸ªæ•°æ®é›†ä¸­ä¸åŒç¤¾åŒºçš„ç²¾ç¡®ç‡å’Œå¬å›ç‡ï¼Œå¹¶æŒ‰çœŸå®ç¤¾åŒºè§„æ¨¡æ’åº"""
    all_sorted_metrics = []  # å­˜å‚¨æ‰€æœ‰æ•°æ®é›†çš„ç¤¾åŒºæŒ‡æ ‡
    max_community_count = 0  # è®°å½•æ•°æ®é›†ä¸­æœ€å¤§çš„ç¤¾åŒºæ•°é‡

    for data in data_list:
        community_stats = data["metrics"]["acc_per_community"]["community_stats"]
        community_metrics = []

        for community_id, stats in community_stats.items():
            TP, FP, FN = stats["TP"], stats["FP"], stats["FN"]
            real_size = TP + FN

            precision = TP / (TP + FP) if (TP + FP) > 0 else 0  # è®¡ç®—ç²¾ç¡®ç‡
            recall = TP / real_size if real_size > 0 else 0  # è®¡ç®—å¬å›ç‡

            community_metrics.append((real_size, precision, recall))

        # æŒ‰çœŸå®ç¤¾åŒºè§„æ¨¡ï¼ˆreal_sizeï¼‰é™åºæ’åº
        community_metrics.sort(reverse=True, key=lambda x: x[0])
        max_community_count = max(max_community_count, len(community_metrics))

        all_sorted_metrics.append(community_metrics)

    return all_sorted_metrics, max_community_count


def compute_average_metrics(all_sorted_metrics, max_community_count):
    """è®¡ç®—æ¯ä¸ªæ’åä¸‹çš„å¹³å‡ç²¾ç¡®ç‡å’Œå¬å›ç‡ï¼ŒåŒæ—¶ç»Ÿè®¡æ¯ä¸ªæ’åçš„ç¤¾åŒºæ•°é‡"""
    aggregated_metrics = [[] for _ in range(max_community_count)]
    rank_counts = [0] * max_community_count  # ç»Ÿè®¡æ¯ä¸ª rank æœ‰å¤šå°‘ä¸ªç¤¾åŒº

    for dataset_metrics in all_sorted_metrics:
        for rank, (size, precision, recall) in enumerate(dataset_metrics):
            aggregated_metrics[rank].append((precision, recall))
            rank_counts[rank] += 1

    avg_results = []
    for rank, metrics in enumerate(aggregated_metrics):
        if metrics:
            avg_precision = np.mean([m[0] for m in metrics])
            avg_recall = np.mean([m[1] for m in metrics])
            avg_results.append((rank + 1, avg_precision, avg_recall, rank_counts[rank]))

    return avg_results


def compute_avg_metrics(data_list):
    """
    è®¡ç®—æ•°æ®é›†çš„å¹³å‡è¿è¡Œæ—¶é—´ã€å¹³å‡ç²¾ç¡®ç‡ã€å¹³å‡å¬å›ç‡ã€å¹³å‡æ¨¡å—åº¦
    """
    runtimes = []
    precisions = []
    recalls = []
    modularities = []

    for data in data_list:
        metrics = data["metrics"]
        runtimes.append(metrics["runtime"])
        precisions.append(metrics["Precision"])
        recalls.append(metrics["Recall"])
        modularities.append(metrics["Modularity"])

    avg_runtime = np.mean(runtimes) if runtimes else 0
    avg_precision = np.mean(precisions) if precisions else 0
    avg_recall = np.mean(recalls) if recalls else 0
    avg_modularity = np.mean(modularities) if modularities else 0

    return avg_runtime, avg_precision, avg_recall, avg_modularity


def show_comparison_precision_recall(
    data_list_1, data_list_2, label_1="Dataset 1", label_2="Dataset 2"
):
    """
    å¯¹æ¯”ä¸¤ç»„æ•°æ®é›†çš„ Precision å’Œ Recallï¼Œå¹¶åœ¨åŒä¸€å¼ å›¾ä¸Šå±•ç¤º
    """

    # è®¡ç®—ä¸¤ç»„æ•°æ®çš„æŒ‡æ ‡
    all_sorted_metrics_1, max_community_count_1 = calculate_precision_recall(
        data_list_1
    )
    avg_results_1 = compute_average_metrics(all_sorted_metrics_1, max_community_count_1)

    all_sorted_metrics_2, max_community_count_2 = calculate_precision_recall(
        data_list_2
    )
    avg_results_2 = compute_average_metrics(all_sorted_metrics_2, max_community_count_2)

    # åˆ›å»º DataFrame å¹¶æ˜¾ç¤ºç»“æœ
    df_1 = pd.DataFrame(
        avg_results_1,
        columns=["Rank", "Avg Precision", "Avg Recall", "Community Count"],
    )
    df_2 = pd.DataFrame(
        avg_results_2,
        columns=["Rank", "Avg Precision", "Avg Recall", "Community Count"],
    )

    print(f"\nğŸ”¹ {label_1} Results:")
    print(df_1.to_string(index=False))
    print(f"\nğŸ”¹ {label_2} Results:")
    print(df_2.to_string(index=False))

    # æå–æ•°æ®
    ranks_1 = [row[0] for row in avg_results_1]
    avg_precision_1 = [row[1] for row in avg_results_1]
    avg_recall_1 = [row[2] for row in avg_results_1]
    community_counts_1 = [row[3] for row in avg_results_1]

    ranks_2 = [row[0] for row in avg_results_2]
    avg_precision_2 = [row[1] for row in avg_results_2]
    avg_recall_2 = [row[2] for row in avg_results_2]
    community_counts_2 = [row[3] for row in avg_results_2]

    # ç»˜åˆ¶å›¾è¡¨
    fig, ax1 = plt.subplots(figsize=(9, 6))

    # ç”» Precision å’Œ Recallï¼ˆæ•°æ®é›†1ï¼‰
    ax1.plot(
        ranks_1,
        avg_precision_1,
        marker="o",
        linestyle="-",
        label=f"{label_1} - Avg Precision",
        color="tab:blue",
    )
    ax1.plot(
        ranks_1,
        avg_recall_1,
        marker="s",
        linestyle="-",
        label=f"{label_1} - Avg Recall",
        color="tab:orange",
    )

    # ç”» Precision å’Œ Recallï¼ˆæ•°æ®é›†2ï¼‰
    ax1.plot(
        ranks_2,
        avg_precision_2,
        marker="^",
        linestyle="--",
        label=f"{label_2} - Avg Precision",
        color="tab:green",
    )
    ax1.plot(
        ranks_2,
        avg_recall_2,
        marker="D",
        linestyle="--",
        label=f"{label_2} - Avg Recall",
        color="tab:red",
    )

    # è½´æ ‡ç­¾
    ax1.set_xlabel("Community Rank")
    ax1.set_ylabel("Score")
    ax1.set_title("Comparison of Average Precision and Recall by Community Rank")
    ax1.legend(loc="upper left")
    ax1.grid(True)

    # åˆ›å»ºç¬¬äºŒä¸ª y è½´ï¼Œæ˜¾ç¤ºç¤¾åŒºæ•°é‡
    ax2 = ax1.twinx()
    ax2.bar(
        ranks_1,
        community_counts_1,
        alpha=0.3,
        color="gray",
        label=f"{label_1} - Community Count",
    )
    ax2.bar(
        ranks_2,
        community_counts_2,
        alpha=0.3,
        color="black",
        label=f"{label_2} - Community Count",
    )

    ax2.set_ylabel("Community Count")

    # æ·»åŠ ç¤¾åŒºæ•°é‡çš„æ ‡ç­¾
    for i, count in enumerate(community_counts_1):
        ax2.text(ranks_1[i], count + 0.2, str(count), ha="center", fontsize=10)

    for i, count in enumerate(community_counts_2):
        ax2.text(ranks_2[i], count + 0.2, str(count), ha="center", fontsize=10)

    ax2.legend(loc="upper right")

    # æ˜¾ç¤ºå›¾è¡¨
    plt.show()


def show_comparison_avg_metrics(
    data_list_1, data_list_2, label_1="Dataset 1", label_2="Dataset 2"
):
    """
    å¯¹æ¯”ä¸¤ç»„æ•°æ®çš„ å¹³å‡è¿è¡Œæ—¶é—´ã€å‡†ç¡®ç‡ã€æ¨¡å—åº¦ï¼Œå¹¶åœ¨åŒä¸€å¼ å›¾ä¸Šå±•ç¤º
    """

    avg_runtime_1, avg_precision_1, avg_recall_1, avg_modularity_1 = (
        compute_avg_metrics(data_list_1)
    )
    avg_runtime_2, avg_precision_2, avg_recall_2, avg_modularity_2 = (
        compute_avg_metrics(data_list_2)
    )

    metrics_df = pd.DataFrame(
        {
            "Metric": ["Runtime", "Precision", "Recall", "Modularity"],
            label_1: [avg_runtime_1, avg_precision_1, avg_recall_1, avg_modularity_1],
            label_2: [avg_runtime_2, avg_precision_2, avg_recall_2, avg_modularity_2],
        }
    )

    print(metrics_df.to_string(index=False))

    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    fig, ax = plt.subplots(figsize=(8, 5))
    bar_width = 0.3
    x_labels = ["Runtime", "Precision", "Recall", "Modularity"]
    x_indexes = np.arange(len(x_labels))

    ax.bar(
        x_indexes - bar_width / 2,
        [avg_runtime_1, avg_precision_1, avg_recall_1, avg_modularity_1],
        width=bar_width,
        label=label_1,
        color="tab:blue",
        alpha=0.7,
    )

    ax.bar(
        x_indexes + bar_width / 2,
        [avg_runtime_2, avg_precision_2, avg_recall_2, avg_modularity_2],
        width=bar_width,
        label=label_2,
        color="tab:orange",
        alpha=0.7,
    )

    # æ·»åŠ æ ‡ç­¾
    ax.set_xlabel("Metrics")
    ax.set_ylabel("Value")
    ax.set_title("Comparison of Average Runtime, Accuracy, and Modularity")
    ax.set_xticks(x_indexes)
    ax.set_xticklabels(x_labels)
    ax.legend()
    ax.grid(True, linestyle="--", alpha=0.6)

    # æ˜¾ç¤ºå›¾è¡¨
    plt.show()


def compare_all_conditions(
    result_dir,
    algorithm_1,
    algorithm_2,
    max_rank_number=10,
    sub_fig_width=5,
    sub_fig_height=4,
    hspace=0.5,
    wspace=0.5,
):
    """
    å¯¹æ¯”æ‰€æœ‰ (3 x 3 x 3) = 27 ç§ä¸åŒå‚æ•°ç»„åˆçš„ Precision-Recall å’Œ Avg Metricsï¼Œ
    å¹¶å°†æ‰€æœ‰å°å›¾æ‹¼æˆä¸€å¼ å¤§å›¾ã€‚

    :param result_dir: æ•°æ®ç›®å½•
    :param algorithm_1: ç®—æ³•1çš„åç§°
    :param algorithm_2: ç®—æ³•2çš„åç§°
    :param max_rank_number: ç»Ÿä¸€ rank é•¿åº¦ï¼ˆé»˜è®¤ä¸º 10ï¼‰
    :param sub_fig_width: å•ä¸ªå­å›¾çš„å®½åº¦
    :param sub_fig_height: å•ä¸ªå­å›¾çš„é«˜åº¦
    :param hspace: å­å›¾ä¹‹é—´çš„çºµå‘é—´è·
    :param wspace: å­å›¾ä¹‹é—´çš„æ¨ªå‘é—´è·
    """

    def plot_precision_recall(
        data_list_1, data_list_2, ax, label, algo_1, algo_2, max_rank_number=10
    ):
        """
        è®¡ç®— Precision-Recallï¼Œå¹¶åœ¨å½“å‰å­å›¾ `ax` ä¸­ç»˜åˆ¶
        åŒæ—¶ç»˜åˆ¶ rank å¯¹åº”çš„ `ç¤¾åŒºæ•°é‡`ï¼ˆä»…ç»˜åˆ¶ä¸€æ ¹æŸ±çŠ¶å›¾ï¼‰
        """

        # è®¡ç®— Precision & Recall
        all_sorted_metrics_1, max_comm_count_1 = calculate_precision_recall(data_list_1)
        avg_results_1 = compute_average_metrics(all_sorted_metrics_1, max_comm_count_1)

        all_sorted_metrics_2, max_comm_count_2 = calculate_precision_recall(data_list_2)
        avg_results_2 = compute_average_metrics(all_sorted_metrics_2, max_comm_count_2)

        # å›ºå®š x è½´é•¿åº¦ä¸º max_rank_number
        ranks = np.arange(1, max_rank_number + 1)

        def pad_or_truncate(arr, length, fill_value=0):
            """å¦‚æœæ•°æ®é•¿åº¦å¤§äº `length`ï¼Œæˆªæ–­ï¼›å¦‚æœä¸è¶³ `length`ï¼Œè¡¥å…¨ `fill_value`"""
            arr = arr[:length]  # æˆªæ–­
            return np.pad(
                arr, (0, max(0, length - len(arr))), constant_values=fill_value
            )  # è¡¥å…¨ `fill_value`

        avg_precision_1 = pad_or_truncate(
            [row[1] for row in avg_results_1], max_rank_number
        )
        avg_recall_1 = pad_or_truncate(
            [row[2] for row in avg_results_1], max_rank_number
        )
        avg_precision_2 = pad_or_truncate(
            [row[1] for row in avg_results_2], max_rank_number
        )
        avg_recall_2 = pad_or_truncate(
            [row[2] for row in avg_results_2], max_rank_number
        )

        # **è®¡ç®—æ¯ä¸ª rank å¯¹åº”çš„ç¤¾åŒºæ•°é‡**ï¼ˆåªç»˜åˆ¶ä¸€æ ¹æŸ±çŠ¶å›¾ï¼‰
        community_counts = pad_or_truncate(
            [row[3] for row in avg_results_1], max_rank_number
        )

        # **åˆ›å»ºç¬¬äºŒä¸ª y è½´** ç”¨äºæ˜¾ç¤º `ç¤¾åŒºæ•°é‡`
        ax2 = ax.twinx()

        # **ç»˜åˆ¶ Precision å’Œ Recall æ›²çº¿**
        ax.plot(
            ranks,
            avg_precision_1,
            linestyle="-",
            label=f"{algo_1} Precision",
            color="tab:blue",
        )
        ax.plot(
            ranks,
            avg_recall_1,
            linestyle="--",
            label=f"{algo_1} Recall",
            color="tab:blue",
        )
        ax.plot(
            ranks,
            avg_precision_2,
            linestyle="-",
            label=f"{algo_2} Precision",
            color="tab:red",
        )
        ax.plot(
            ranks,
            avg_recall_2,
            linestyle="--",
            label=f"{algo_2} Recall",
            color="tab:red",
        )

        # **ç»˜åˆ¶ç¤¾åŒºæ•°é‡çš„æŸ±çŠ¶å›¾ï¼ˆåªæœ‰ä¸€æ ¹ï¼‰**
        ax2.bar(
            ranks,
            community_counts,
            width=0.4,
            alpha=0.4,
            color="gray",
            label="Community Count",
        )

        # **è®¾ç½®åæ ‡è½´ä¿¡æ¯**
        ax.set_xlabel("Community Rank", fontsize=12)
        ax.set_ylabel("Precision / Recall", fontsize=12)
        ax2.set_ylabel("Community Count", fontsize=12)

        ax.set_xticks(ranks)
        ax2.set_xticks(ranks)

        # **åœ¨æŸ±çŠ¶å›¾ä¸Šæ˜¾ç¤º `ç¤¾åŒºæ•°é‡`**
        for i, count in enumerate(community_counts):
            ax2.text(ranks[i], count + 0.2, str(count), ha="center", fontsize=10)

        ax.set_title(label, fontsize=14)

    def plot_avg_metrics(data_list_1, data_list_2, ax, label, algo_1, algo_2):
        """
        è®¡ç®—å¹³å‡ Metrics å¹¶ç»˜åˆ¶åˆ°å½“å‰å­å›¾ `ax`
        - `Runtime` ä½¿ç”¨ **å·¦ Y è½´**
        - `Precision, Recall, Modularity` ä½¿ç”¨ **å³ Y è½´**ï¼ŒèŒƒå›´å›ºå®šä¸º `0-1`
        """

        def compute_avg_metrics(data_list):
            runtimes, precisions, recalls, modularities = [], [], [], []
            for data in data_list:
                metrics = data["metrics"]
                runtimes.append(metrics["runtime"])
                precisions.append(metrics["Precision"])
                recalls.append(metrics["Recall"])
                modularities.append(metrics["Modularity"])

            return (
                np.mean(runtimes),
                np.mean(precisions),
                np.mean(recalls),
                np.mean(modularities),
            )

        avg_runtime_1, avg_precision_1, avg_recall_1, avg_modularity_1 = (
            compute_avg_metrics(data_list_1)
        )
        avg_runtime_2, avg_precision_2, avg_recall_2, avg_modularity_2 = (
            compute_avg_metrics(data_list_2)
        )

        # **X è½´æ ‡ç­¾**
        x_labels_1 = ["Runtime"]
        x_labels_2 = ["Precision", "Recall", "Modularity"]

        x_indexes_1 = np.array([0])  # Runtime åœ¨ X è½´çš„ä½ç½®
        x_indexes_2 = np.array([1, 2, 3])  # å…¶å®ƒ Metrics åœ¨ X è½´çš„ä½ç½®

        # **åˆ›å»ºç¬¬äºŒä¸ª Y è½´**ï¼ˆå³ä¾§ï¼‰
        ax2 = ax.twinx()

        # **ç»˜åˆ¶ Runtimeï¼ˆå·¦ Y è½´ï¼‰**
        ax.bar(
            x_indexes_1 - 0.2,
            [avg_runtime_1],
            width=0.4,
            label=f"{algo_1} Runtime",
            alpha=0.8,
            color="tab:blue",
        )
        ax.bar(
            x_indexes_1 + 0.2,
            [avg_runtime_2],
            width=0.4,
            label=f"{algo_2} Runtime",
            alpha=0.8,
            color="tab:orange",
        )

        # **ç»˜åˆ¶ Precision, Recall, Modularityï¼ˆå³ Y è½´ï¼‰**
        ax2.bar(
            x_indexes_2 - 0.2,
            [avg_precision_1, avg_recall_1, avg_modularity_1],
            width=0.4,
            label=f"{algo_1} Precision/Recall/Modularity",
            alpha=0.7,
            color="tab:green",
        )

        ax2.bar(
            x_indexes_2 + 0.2,
            [avg_precision_2, avg_recall_2, avg_modularity_2],
            width=0.4,
            label=f"{algo_2} Precision/Recall/Modularity",
            alpha=0.7,
            color="tab:red",
        )

        # **è®¾ç½® X è½´æ ‡ç­¾**
        ax.set_xticks(np.concatenate((x_indexes_1, x_indexes_2)))
        ax.set_xticklabels(x_labels_1 + x_labels_2, fontsize=12)

        # **è®¾ç½® Y è½´èŒƒå›´**
        ax2.set_ylim(0, 1)  # **å³ Y è½´èŒƒå›´å›ºå®šåœ¨ 0-1**
        ax.set_ylim(0, max(avg_runtime_1, avg_runtime_2) * 1.2)  # **å·¦ Y è½´è‡ªåŠ¨è°ƒæ•´**

        # **è®¾ç½® Y è½´æ ‡ç­¾**
        ax.set_ylabel("Runtime (seconds)", fontsize=12, color="tab:blue")
        ax2.set_ylabel(
            "Precision / Recall / Modularity", fontsize=12, color="tab:green"
        )

        ax.set_title(label, fontsize=14)

        # **åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼**
        ax.text(
            x_indexes_1[0] - 0.1,
            avg_runtime_1 + 0.01,
            f"{avg_runtime_1:.3f}",
            ha="center",
            fontsize=10,
            color="tab:blue",
        )
        ax.text(
            x_indexes_1[0] + 0.1,
            avg_runtime_2 + 0.01,
            f"{avg_runtime_2:.3f}",
            ha="center",
            fontsize=10,
            color="tab:orange",
        )

        for i, v in enumerate([avg_precision_1, avg_recall_1, avg_modularity_1]):
            ax2.text(
                x_indexes_2[i] - 0.1,
                v + 0.02,
                f"{v:.3f}",
                ha="center",
                fontsize=10,
                color="tab:green",
            )

        for i, v in enumerate([avg_precision_2, avg_recall_2, avg_modularity_2]):
            ax2.text(
                x_indexes_2[i] + 0.1,
                v + 0.02,
                f"{v:.3f}",
                ha="center",
                fontsize=10,
                color="tab:red",
            )

        # **ä¼˜åŒ– X è½´é—´è·**
        ax.margins(x=0.1)

        # **è¿”å› legend ä¿¡æ¯**
        handles1, labels1 = ax.get_legend_handles_labels()  # å·¦ Y è½´ legend
        handles2, labels2 = ax2.get_legend_handles_labels()  # å³ Y è½´ legend
        return handles1 + handles2, labels1 + labels2  # **åˆå¹¶ legend**

    # å¯èƒ½çš„å‚æ•°å–å€¼
    point_levels = ["level1", "level2", "level3"]
    density_levels = ["level1", "level2", "level3"]
    community_size_levels = ["level1", "level2", "level3"]

    # **åŠ¨æ€è®¡ç®—å¤§å›¾å°ºå¯¸**
    fig_width = 9 * sub_fig_width + (9 - 1) * wspace
    fig_height = 3 * sub_fig_height + (3 - 1) * hspace

    fig1, axes1 = plt.subplots(
        3, 9, figsize=(fig_width, fig_height), constrained_layout=True
    )  # Precision-Recall
    fig2, axes2 = plt.subplots(
        3, 9, figsize=(fig_width, fig_height), constrained_layout=True
    )  # Avg Metrics

    plot_index = 0  # è®°å½•å­å›¾ç´¢å¼•

    for p in point_levels:
        for d in density_levels:
            for c in community_size_levels:
                label = f"point-{p}, density-{d}, community-{c}"

                # è¯»å–ä¸¤ç»„æ•°æ®
                data_1 = read_data(
                    result_dir,
                    algorithm=algorithm_1,
                    point_level=p,
                    density_level=d,
                    community_size_level=c,
                )
                data_2 = read_data(
                    result_dir,
                    algorithm=algorithm_2,
                    point_level=p,
                    density_level=d,
                    community_size_level=c,
                )

                if not data_1 or not data_2:
                    print(f"âš ï¸ è·³è¿‡ {label}ï¼ˆæ•°æ®ç¼ºå¤±ï¼‰")
                    continue

                print(f"ğŸ” å¤„ç† {label}...")

                # è·å–å½“å‰å­å›¾
                row, col = divmod(plot_index, 9)  # 3è¡Œ9åˆ—çš„ç´¢å¼•
                ax1 = axes1[row, col]  # Precision-Recall å­å›¾
                ax2 = axes2[row, col]  # Avg Metrics å­å›¾

                # è®¡ç®— Precision-Recall å¹¶ç»˜åˆ¶æ›²çº¿
                plot_precision_recall(
                    data_1,
                    data_2,
                    ax1,
                    label,
                    algorithm_1,
                    algorithm_2,
                    max_rank_number,
                )

                # è®¡ç®— Avg Metrics å¹¶ç»˜åˆ¶æŸ±çŠ¶å›¾
                plot_avg_metrics(data_1, data_2, ax2, label, algorithm_1, algorithm_2)

                # è®¾ç½®å­å›¾åæ ‡è½´æ ‡ç­¾
                ax1.set_xlabel("Rank", fontsize=12)
                ax1.set_ylabel("Score", fontsize=12)

                ax2.set_xlabel("Metric", fontsize=12)
                ax2.set_ylabel("Value", fontsize=12)

                plot_index += 1  # é€’å¢ç´¢å¼•

    # **è®¾ç½®å¤§å›¾æ ‡é¢˜**
    fig1.suptitle(
        "Precision-Recall Comparison Across 27 Conditions",
        fontsize=24,
        fontweight="bold",
    )
    fig2.suptitle(
        "Average Metrics Comparison Across 27 Conditions",
        fontsize=24,
        fontweight="bold",
    )

    # **ä»…åœ¨å¤§å›¾çº§åˆ«æ·»åŠ å›¾ä¾‹**
    handles1, labels1 = axes1[0, 0].get_legend_handles_labels()
    fig1.legend(handles1, labels1, loc="upper right", fontsize=16)

    # **ä¿®å¤ `fig2` ç¼ºå°‘ `legend`**
    handles2, labels2 = [], []
    for i in range(3):
        for j in range(9):
            legend_handles, legend_labels = axes2[
                i, j
            ].get_legend_handles_labels()  # **è·å– `legend`**
            handles2.extend(legend_handles)
            labels2.extend(legend_labels)

    # **å»é‡ï¼Œç¡®ä¿ `metrics` å›¾çš„å›¾ä¾‹å®Œæ•´**
    unique_legend = dict(zip(labels2, handles2))
    fig2.legend(
        unique_legend.values(), unique_legend.keys(), loc="upper right", fontsize=16
    )

    # **ä¿å­˜å›¾åƒ**
    fig1.savefig(
        r"result\precision_recall_comparison_grid.png", dpi=400, bbox_inches="tight"
    )
    fig2.savefig(
        r"result\avg_metrics_comparison_grid.png", dpi=400, bbox_inches="tight"
    )

    # **æ˜¾ç¤ºå›¾è¡¨**
    plt.show()


if __name__ == "__main__":
    # ç»“æœæ–‡ä»¶ç›®å½•
    result_dir = r"D:\code\FYP\CommunityDetection\result_collection\result\test"
    # æ˜¯å¦æ¯”è¾ƒæ‰€æœ‰ç»„åˆï¼ˆ27ç§ï¼‰
    compare_all_combinations = True
    # å¯¹æ¯”çš„ä¸¤ç§ç®—æ³•
    algorithm_name_1 = "Leiden_Rarev0.01"
    algorithm_name_2 = "Leiden"
    data_list_1 = read_data(
        result_dir,
        algorithm=algorithm_name_1,
    )
    data_list_2 = read_data(
        result_dir,
        algorithm=algorithm_name_2,
    )

    if compare_all_combinations:
        # æ‰¹é‡å¯¹æ¯” 3*3*3 = 27 ç§æƒ…å†µ
        compare_all_conditions(
            result_dir, algorithm_name_1, algorithm_name_2, max_rank_number=10
        )
    else:

        show_comparison_precision_recall(
            data_list_1, data_list_2, label_1=algorithm_name_1, label_2=algorithm_name_2
        )
        show_comparison_avg_metrics(
            data_list_1, data_list_2, label_1=algorithm_name_1, label_2=algorithm_name_2
        )
